# ğŸ­ Real-time Facial Emotion Recognition

A professional real-time facial emotion recognition system using deep learning with CNN architecture. Detects and classifies human emotions from live webcam feeds with beautiful visualization and real-time statistics.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.10+-orange.svg)
![OpenCV](https://img.shields.io/badge/OpenCV-4.5+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## âœ¨ Features

- ğŸ¯ **Real-time Detection**: Smooth emotion detection from webcam feed
- ğŸ“Š **Live Statistics**: Real-time FPS, session duration, emotion distribution
- ğŸ¨ **Professional UI**: Beautiful visualization with confidence bars
- ğŸ“· **Screenshot Capture**: Save moments with one keypress
- ğŸ§  **Custom CNN Model**: Train your own model with the FER2013 dataset
- ğŸ“ˆ **Training Analytics**: Comprehensive training visualization and metrics

## ğŸ“ Project Structure

```
Real-time-Facial-Emotion-Recognition/
â”œâ”€â”€ main.py                     # ğŸš€ Application entry point
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py             # Configuration settings
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ emotion_detector.py     # Main detection system
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ face_detector.py        # Face detection module
â”‚   â”œâ”€â”€ visualizer.py           # UI visualization
â”‚   â””â”€â”€ data_loader.py          # Dataset utilities
â”œâ”€â”€ training/
â”‚   â””â”€â”€ emotion_recognition_training.ipynb  # ğŸ““ Training notebook
â”œâ”€â”€ models/                     # Trained models directory
â”œâ”€â”€ data/                       # Dataset directory
â”œâ”€â”€ screenshots/                # Captured screenshots
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ­ Supported Emotions

| Emotion | Color | Description |
|---------|-------|-------------|
| ğŸ˜  Angry | ğŸ”´ Red | Displeasure, frustration |
| ğŸ¤¢ Disgust | ğŸŸ¢ Green | Strong dislike, aversion |
| ğŸ˜¨ Fear | ğŸŸ£ Purple | Apprehension, anxiety |
| ğŸ˜Š Happy | ğŸŸ¡ Yellow | Joy, satisfaction |
| ğŸ˜¢ Sad | ğŸ”µ Blue | Sorrow, unhappiness |
| ğŸ˜² Surprise | ğŸŸ  Orange | Astonishment, shock |
| ğŸ˜ Neutral | âšª Gray | Calm, no strong emotion |

## ğŸš€ Quick Start

### 1. Clone & Install

```bash
git clone https://github.com/AzizBahloul/Real-time-Facial-Emotion-Recognition.git
cd Real-time-Facial-Emotion-Recognition

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

### 2. Train the Model (First Time)

Open the training notebook and run all cells:
```bash
jupyter notebook training/emotion_recognition_training.ipynb
```

The notebook will:
- Download the FER2013 dataset using `kagglehub`
- Visualize the dataset distribution
- Train a CNN model
- Save the model to `models/`

### 3. Run the Application

```bash
python main.py
```

### Command Line Options

```bash
python main.py --help

# Options:
#   --model, -m PATH    Custom model path
#   --camera, -c ID     Camera device ID (default: 0)
#   --list-cameras      List available cameras
```

## âŒ¨ï¸ Controls

| Key | Action |
|-----|--------|
| `Q` | Quit application |
| `S` | Take screenshot |
| `R` | Reset statistics |

## ğŸ“Š Dataset

This project uses the **FER2013** dataset from Kaggle:
- 48x48 pixel grayscale images
- 7 emotion classes
- ~28,709 training images
- ~3,589 test images

The dataset is automatically downloaded using `kagglehub`:
```python
import kagglehub
path = kagglehub.dataset_download("msambare/fer2013")
```

## ğŸ§  Model Architecture

Custom CNN with 4 convolutional blocks:
- Conv2D + BatchNorm + MaxPool + Dropout (64 â†’ 128 â†’ 256 â†’ 512 filters)
- Dense layers with dropout for regularization
- Softmax output for 7-class classification

## ğŸ“ˆ Training Features

The training notebook includes:
- ğŸ“Š Dataset visualization and class distribution
- ğŸ”„ Data augmentation (rotation, shift, flip, zoom)
- âš–ï¸ Class weights for imbalanced data
- ğŸ“‰ Learning rate scheduling
- ğŸ›‘ Early stopping
- ğŸ“‹ Confusion matrix and classification report
- ğŸ’¾ Multiple model export formats (.keras, .h5, SavedModel)

## ğŸ› ï¸ Requirements

- Python 3.8+
- TensorFlow 2.10+
- OpenCV 4.5+
- NumPy, Pandas, Matplotlib, Seaborn
- kagglehub (for dataset download)
- scikit-learn (for evaluation metrics)

See `requirements.txt` for complete list.

## ğŸ“· Screenshots

The application features:
- Real-time face detection with corner-style bounding boxes
- Emotion label with confidence percentage
- Live confidence bar chart for all emotions
- Statistics panel with FPS, session time, and emotion distribution

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- FER2013 Dataset: [Kaggle](https://www.kaggle.com/datasets/msambare/fer2013)
- OpenCV for face detection
- TensorFlow/Keras for deep learningbash
